{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a004adb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with PDF:  231.pdf\n",
      "{'4512.pdf': {'ERROR': 'Process OK', 'characters': 1604, 'words': 256, 'sentences': 14, 'Score': 75, 'Issues left': 18, 'Critical': 8, 'Unique Words': 41, 'Rare Words': 36, 'Word Length': 4.6, 'Sentence Length': 18.3, 'Correctness': 8, 'Misuse of modi\\x00ers': 1, 'Wrong or missing prepositions': 1, 'Comma misuse within clauses': 1, 'Confused words': 1, 'Incorrect verb forms': 1, 'Determiner use (a/an/the/this, etc.)': 2, 'Incorrect noun number': 1}, '111.pdf': {'ERROR': 'Process OK', 'characters': 1712, 'words': 243, 'sentences': 14, 'Score': 79, 'Issues left': 18, 'Critical': 1, 'Unique Words': 46, 'Rare Words': 44, 'Word Length': 5.9, 'Sentence Length': 17.4, 'Clarity': 1, 'Wordy sentences': 1, 'Correctness': 1, 'Incorrect noun number': 1}, '321.pdf': {'ERROR': 'Process OK', 'characters': 2166, 'words': 306, 'sentences': 15, 'Score': 86, 'Issues left': 15, 'Critical': 1, 'Unique Words': 41, 'Rare Words': 38, 'Word Length': 5.9, 'Sentence Length': 20.4, 'Clarity': 1, 'Wordy sentences': 1, 'Correctness': 1, 'Determiner use (a/an/the/this, etc.)': 1}, '544.pdf': {'ERROR': 'Process OK', 'characters': 1731, 'words': 273, 'sentences': 13, 'Score': 75, 'Issues left': 20, 'Critical': 8, 'Unique Words': 51, 'Rare Words': 37, 'Word Length': 5.0, 'Sentence Length': 21.0, 'Correctness': 8, 'Comma misuse within clauses': 6, 'Incorrect noun number': 1, 'Determiner use (a/an/the/this, etc.)': 1, 'Clarity': 1, 'Wordy sentences': 1}, '231.pdf': {'ERROR': 'Error with PDF', 'characters': 1854, 'words': 287, 'sentences': 15, 'Score': 83, 'Issues left': 17, 'Critical': 3, 'Unique Words': 40, 'Rare Words': 41, 'Word Length': 5.1, 'Sentence Length': 19.1, 'Correctness': 3, 'Determiner use (a/an/the/this, etc.)': 2, 'Faulty subject-verb agreement': 1}, '541.pdf': {'ERROR': 'Process OK', 'characters': 1886, 'words': 291, 'sentences': 16, 'Score': 97, 'Issues left': 6, 'Critical': 3, 'Unique Words': 36, 'Rare Words': 47, 'Word Length': 4.5, 'Sentence Length': 18.2, 'Correctness': 3, 'Determiner use (a/an/the/this, etc.)': 1, 'Wrong or missing prepositions': 1, 'Confused words': 1}}\n",
      "####################################################################################################\n",
      "Punctuation in compound/complex - add -> sentences\n",
      "Total files in /Users/yoavbrezinov/Desktop/McGill/LDI/Gabi/GPT_MODEL/TESTING/FINAL_TEST/ --> 7\n",
      "PDF files: 6\n",
      "PDFs without Critical mistakes: 0\n",
      "Bed PDFs: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join, exists\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "reg_exp1='\\d+[,.]?\\d*' #number \n",
    "reg_exp2=r'\\S+' #word\n",
    "reg_exp3=r'.*' #line\n",
    "reg_exp4=r'\\D+' #non digits only\n",
    "\n",
    "def find_exp(exp,text):\n",
    "    match=re.search(exp,text)\n",
    "    return re.findall(reg_exp1,text[match.end():])\n",
    "def find_ocurrence(exp,text,num):\n",
    "    loc=re.finditer(exp,text)\n",
    "    k=0\n",
    "    temp=-1\n",
    "    for i in loc:\n",
    "        k+=1\n",
    "        if k==num:\n",
    "            return i.start()\n",
    "    return -1\n",
    "def to_excel(filename,dictionary):\n",
    "    df = pd.DataFrame(dictionary)\n",
    "    df.to_excel(filename, index=True, header=True)\n",
    "def read_pdf(filename):\n",
    "    output=\"\"\n",
    "    if exists(filename) and isfile(filename) and filename.endswith('.pdf'):\n",
    "        pdf1=open(filename,'rb')\n",
    "        pd_read=PyPDF2.PdfFileReader(pdf1)\n",
    "        pages=pd_read.numPages\n",
    "        for i in range(0,pages):\n",
    "            page1=pd_read.getPage(i)\n",
    "            output+=page1.extractText()\n",
    "        pdf1.close()\n",
    "    return output\n",
    "def read_digit(text,location): # reads the numbers befor a location in the text and returns the number (integer)\n",
    "    if text=='' or location==-1:\n",
    "        return 0\n",
    "    temp=location-1\n",
    "    number=0\n",
    "    dig_counter=0\n",
    "    while temp>=0 and not text[temp].isdigit():\n",
    "        temp-=1\n",
    "    while temp>=0 and text[temp].isdigit():\n",
    "        number=int(text[temp])*(10**dig_counter)+number\n",
    "        temp-=1\n",
    "        dig_counter+=1\n",
    "    return number\n",
    "    \n",
    "mypath='/Users/yoavbrezinov/Desktop/McGill/LDI/Gabi/GPT_MODEL/TESTING/FINAL_TEST/'\n",
    "allfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "all_data={}\n",
    "data={'characters':0, 'words':0, 'sentences':0,'Score':0, 'Issues left':0, \n",
    "      'Critical':0, 'Unique Words':0, 'Rare Words':0, 'Word Length':0, 'Sentence Length':0, 'ERROR':''}\n",
    "total_files=0\n",
    "pdf_files=0\n",
    "no_crit_err=0\n",
    "bed_pdfs=0\n",
    "for f in allfiles:\n",
    "    total_files+=1\n",
    "    if f.endswith('.pdf'):\n",
    "        pdf_files+=1\n",
    "        all_data[f]={}\n",
    "        all_data[f]['ERROR']=''\n",
    "        output=read_pdf(join(mypath,f))\n",
    "        nums=find_exp('General metrics',output)\n",
    "        all_data[f]['characters']=int(nums[0].replace(\",\",\"\"))\n",
    "        all_data[f]['words']=int(nums[1].replace(\",\",\"\"))\n",
    "        all_data[f]['sentences']=int(nums[2].replace(\",\",\"\"))\n",
    "        nums=find_exp('Score Writing Issues',output)\n",
    "        all_data[f]['Score']=int(nums[0].replace(\",\",\"\"))\n",
    "        nums=find_exp('by Grammarly',output)\n",
    "        all_data[f]['Issues left']=int(nums[0].replace(\",\",\"\"))\n",
    "        temp3=find_ocurrence('Critical',output,1)\n",
    "        if temp3!=-1 and not output[temp3-2].isdigit():\n",
    "            all_data[f]['Critical']=0\n",
    "        else:\n",
    "            all_data[f]['Critical']=int(nums[1].replace(\",\",\"\"))\n",
    "        nums=find_exp('Unique Words',output)\n",
    "        all_data[f]['Unique Words']=int(nums[0].replace(\",\",\"\"))\n",
    "        nums=find_exp('Rare Words',output)\n",
    "        all_data[f]['Rare Words']=int(nums[0].replace(\",\",\"\"))\n",
    "        nums=find_exp('Word Length',output)\n",
    "        all_data[f]['Word Length']=float(nums[0].replace(\",\",\"\"))\n",
    "        all_data[f]['Sentence Length']=float(nums[1].replace(\",\",\"\"))\n",
    "        #Writing Issues#\n",
    "        if all_data[f]['Critical']==0:\n",
    "            loc=find_ocurrence('Clarity',output,1)\n",
    "            if loc!=-1:\n",
    "                dig=read_digit(output,loc)\n",
    "                all_data[f]['Clarity']=dig\n",
    "                all_data[f]['Wordy sentences']=dig\n",
    "            no_crit_err+=1\n",
    "            print(\"No critical errors in: \",f)\n",
    "            all_data[f]['ERROR']='No critical mistakes'\n",
    "            continue\n",
    "        temp1=find_ocurrence('Writing Issues',output,2)\n",
    "        if not output[temp1+len('Writing Issues')+1].isdigit():\n",
    "            bed_pdfs+=1\n",
    "            print(\"Error with PDF: \",f)\n",
    "            all_data[f]['ERROR']='Error with PDF'\n",
    "            bed_text='Measures vocabulary diversity by calculating the\\npercentage of words used only once in your\\ndocumentunique words'\n",
    "            output=output.replace(bed_text,'')\n",
    "        temp2=find_ocurrence('Report',output,3)\n",
    "        words=re.findall(reg_exp3,output[temp1:temp2])\n",
    "        del words[0]\n",
    "        for word in words:\n",
    "            if word!='' and word[0].isdigit():\n",
    "                num=re.findall(reg_exp1,word)\n",
    "                expr=re.findall(reg_exp4,word)\n",
    "                all_data[f][expr[0][1:]]=int(num[0])\n",
    "        if all_data[f]['ERROR']=='':\n",
    "            all_data[f]['ERROR']='Process OK'\n",
    "print(all_data)\n",
    "print('#'*100)\n",
    "print(\"Punctuation in compound/complex - add -> sentences\")\n",
    "print(f'Total files in {mypath} --> {total_files}\\nPDF files: {pdf_files}\\nPDFs without Critical mistakes: {no_crit_err}\\nBed PDFs: {bed_pdfs}\\n')\n",
    "to_excel(mypath+'/25TEST_ORIGINAL.xlsx',all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe45463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(read_pdf(mypath+'4.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d7437c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819fa94f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3e1a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950aed71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eeb216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf280ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80abf525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d27179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbf09df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68fb44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26247db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ac564a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
